{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a72c471e-fe57-4c29-a6d0-8b4568aa55ed",
   "metadata": {},
   "source": [
    "# Arxiv quick survey generator\n",
    "\n",
    "Sometimes when I want to learn more about a topic by reading some papers, it is hard to find which papers are worth reading. This script uses chatgpt to help with that.\n",
    "\n",
    "The approach is simple:\n",
    "1. Given the topic of interest, query arxiv for documents.\n",
    "2. Extract the abstract and conclusion from the pdf.\n",
    "3. Send them to chat-gpt to answer some basic questions about the article\n",
    "4. Rresent the results in a table and save them in a csv file.\n",
    "\n",
    "## TODO\n",
    "- add the fname in the summary generated\n",
    "- maintain a cache of previously seen papers and reuse if they show up again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b658af7-832b-43ec-a6fa-c6b7a479c868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import openai\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pypdfium2 as pdfium   # used to parse the pdf\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import random\n",
    "import google.generativeai as palm\n",
    "import google.generativeai.types.safety_types as safety_types\n",
    "import logging\n",
    "\n",
    "gMODEL = 'models/text-bison-001'\n",
    "g_api_key = os.environ['PALM_API_KEY']\n",
    "palm.configure(api_key=g_api_key)\n",
    "gEMODEL = 'models/embedding-gecko-001'\n",
    "\n",
    "SAFETY = [\n",
    "    {'category': safety_types.HarmCategory.HARM_CATEGORY_DEROGATORY,\n",
    "     'threshold': safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {'category': safety_types.HarmCategory.HARM_CATEGORY_TOXICITY,\n",
    "     'threshold': safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {'category': safety_types.HarmCategory.HARM_CATEGORY_VIOLENCE,\n",
    "     'threshold': safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {'category': safety_types.HarmCategory.HARM_CATEGORY_SEXUAL,\n",
    "     'threshold': safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {'category': safety_types.HarmCategory.HARM_CATEGORY_MEDICAL,\n",
    "     'threshold': safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "    {'category': safety_types.HarmCategory.HARM_CATEGORY_DANGEROUS,\n",
    "     'threshold': safety_types.HarmBlockThreshold.BLOCK_NONE,\n",
    "    },\n",
    "]\n",
    "axClient = arxiv.Client()\n",
    "\n",
    "EMODEL = \"text-embedding-ada-002\"  # embedding model is openai\n",
    "#CMODEL = \"gpt-3.5-turbo\"  # chat model\n",
    "CMODEL = \"gpt-4\"\n",
    "SEARCHMULT = 2  # multiply this by the desired number of papers for search\n",
    "PDFCACHEDIR = '/tmp/pdfs/'\n",
    "os.makedirs(PDFCACHEDIR, exist_ok=True)\n",
    "SIMTHRESHOLD = 0.5\n",
    "\n",
    "DEBUG = 1\n",
    "\n",
    "# Extracting conclusions and possibly abstracts are done with heuristic methods that \n",
    "# use these parameters\n",
    "MAXTITLELEN = 50 # title of conclusion can be as long as this\n",
    "MINCONCLLEN = 1000  # epect conclusions to be longer than these many chars\n",
    "TTLEXP = 100  # to verify we have a section title, lookahead and back\n",
    "\n",
    "RETRIES = 3  # rety getting papers\n",
    "\n",
    "BASEDIR = os.getcwd()\n",
    "LOGFILE = os.path.join(BASEDIR, 'log/genSurvey.log')\n",
    "\n",
    "logging.basicConfig(format='%(message)s',\n",
    "                    filename=LOGFILE, \n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "\n",
    "def getPapers(uquery: str = 'tree search', \n",
    "              num: int = 10, \n",
    "              startDate: str = None,\n",
    "              endDate: str = None,\n",
    "              llm: str = 'google', \n",
    "              simThreshold: float = SIMTHRESHOLD) -> list[dict()]:\n",
    "    \"\"\"\n",
    "    - Queries arxiv for the topic of interest\n",
    "    - **the query is a comma-separated list of terms**\n",
    "    - **terms will be searched for in the abstract and we get the conjunction**\n",
    "    - finds cosine similarity between the summary and the query string\n",
    "    - returns a list of {paper, cosineSim} in order of decreasing sim\n",
    "    TBD: whether this ordering is differnet from the arxiv ordering\n",
    "    \"\"\"\n",
    "    logging.info(f\"getPapers, query: {uquery}, num: {num}\")\n",
    "    terms = uquery.split(',')\n",
    "    query = f\"abs:{terms[0].strip()}\"\n",
    "    for t in terms[1:]:\n",
    "        query += f\" AND abs:{t.strip()}\"\n",
    "    if startDate is not None and endDate is not None:\n",
    "        axquery = f\"ti:{query} AND submittedDate:[{startDate} TO {endDate}]\"\n",
    "    else:\n",
    "        axquery = query\n",
    "    logging.debug(f\"arxiv query: {axquery}\")\n",
    "    print(f\"arxiv query: {axquery}\")\n",
    "    try:\n",
    "        search = arxiv.Search(\n",
    "          query = axquery,\n",
    "          max_results = num * SEARCHMULT,\n",
    "          sort_by = arxiv.SortCriterion.Relevance\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Cannot get arxiv data\\n{str(e)}\")\n",
    "        print(f\"Cannot get arxiv data\\n{str(e)}\")\n",
    "        return []\n",
    "    results = axClient.results(search)\n",
    "    logging.debug(f\"Arxiv returns\")\n",
    "    qel = getEmbedding(query, llm)\n",
    "    qEmb = np.array(qel)\n",
    "    logging.debug(f\"Embedding: {str(qEmb.shape)}\")\n",
    "    qNorm = norm(qEmb)\n",
    "    docNscores = []\n",
    "    for r in results:\n",
    "        rs = {'paper': r}\n",
    "        logging.debug(f\"Proessing {r.title}\")\n",
    "        pEmb = np.array(getEmbedding(r.summary, llm))\n",
    "        #pEmb = np.array(openai.Embedding.create(input = r.summary,\n",
    "        #                                 model = EMODEL)['data'][0]['embedding'])\n",
    "        rs['score'] = np.dot(pEmb, qEmb)/(qNorm * norm(pEmb))\n",
    "        if rs['score'] >= simThreshold:\n",
    "            docNscores.append(rs)\n",
    "    docNscores.sort(key=lambda x: x['score'], reverse=True)\n",
    "    return docNscores\n",
    "\n",
    "def getEmbedding(query:str = '',\n",
    "                 llm:str = 'palm')->list[float]:\n",
    "    logging.debug(f\"Embedding {query}\")\n",
    "    if llm == 'openai':\n",
    "        qel = openai.Embedding.create(input=query, \n",
    "                                      model=EMODEL)['data'][0]['embedding']\n",
    "    elif llm == 'google':\n",
    "        qel = palm.generate_embeddings(model = gEMODEL, text = query)['embedding']\n",
    "    else:\n",
    "        print('Unknown embedding')\n",
    "        qel= None\n",
    "    return qel\n",
    "\n",
    "def addChunks(docNscores: list[dict()],\n",
    "              noConclusionsOK: bool = False,\n",
    "              dumpDir:str = PDFCACHEDIR,) -> list[dict()]:\n",
    "    \"\"\"\n",
    "     Adds abstract and conclusion to the input data\n",
    "    \"\"\"\n",
    "    logging.info(\"addChunks\")\n",
    "    dsc = []\n",
    "    success = False\n",
    "    cnt = 0\n",
    "    for ds in docNscores:\n",
    "        cnt = 0\n",
    "        success = False\n",
    "        fname = os.path.join(dumpDir, ds['paper']._get_default_filename())\n",
    "        if os.path.isfile(fname):\n",
    "            success = True\n",
    "        while not success and cnt < RETRIES:\n",
    "            cnt += 1\n",
    "            try:\n",
    "                fname = ds['paper'].download_pdf(dumpDir)\n",
    "                logging.debug(f\"Done download {ds['paper']}\")\n",
    "                success = True\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            time.sleep(0.5 + random.random() * 2)\n",
    "        if not success:\n",
    "            logging.error(f\"Cannot download {ds['paper'].title}\")\n",
    "            continue\n",
    "        pdf = pdfium.PdfDocument(fname)\n",
    "        # the summary is supposed to be the abstract\n",
    "        ds['abstract'] = ds['paper'].summary\n",
    "        # in case it is not present, we try to find it\n",
    "        if ds['abstract'].strip() == '':\n",
    "            abs = getAbs(pdf, False)\n",
    "            if abs == '':\n",
    "                print(f\"eliminating {ds['paper'].title} because no summary (abstract) provided or found\")\n",
    "                continue\n",
    "        concl = getConcl(pdf, False)\n",
    "        ds['conclusion'] = concl\n",
    "        if concl != '' or noConclusionsOK: \n",
    "            dsc.append(ds)\n",
    "        else:\n",
    "            print(f\"eliminating {ds['paper'].title} because no conclusion found\")\n",
    "    return dsc\n",
    "\n",
    "def getConcl(pdf, hailMary=False):\n",
    "    \"\"\"\n",
    "    Assume the conclusion is between \"Conclusion\" or \"Discussion\" and \"References\"\n",
    "    This is a heuristic approach to the probelm. A ML approach might get better results.\n",
    "    This works good enough for a v0.\n",
    "    \"\"\"\n",
    "    logging.info('Trying to find conclusion from pdf')\n",
    "    nPages = len(pdf)\n",
    "    done = False\n",
    "    pIdx = nPages - 1\n",
    "    conclusion = ''\n",
    "    startIdx = -1\n",
    "    endIdx = -1\n",
    "    re1 = re.compile('\\W*conclusion.*?\\n.*')   # and is < MAXCONCLTLEN\n",
    "    # try fo find the referenes.\n",
    "    while pIdx > -1:\n",
    "        page = pdf[pIdx].get_textpage().get_text_range()\n",
    "        lp = page.lower()\n",
    "        spx = 0\n",
    "        epx = len(lp)\n",
    "        while spx < epx:\n",
    "            if (rpos := lp[spx:epx].find('reference')) > -1:\n",
    "                if looksLikeTitle(lp, rpos, 'reference'):\n",
    "                    endIdx = rpos\n",
    "                    break\n",
    "                else: spx += rpos + 1\n",
    "            else: \n",
    "                break\n",
    "            time.sleep(1)\n",
    "        if endIdx == -1:\n",
    "            pIdx -= 1\n",
    "        else: break\n",
    "    # should look fro all instances of conclusion on each page\n",
    "    # should also look for 'discussion'\n",
    "    if (cpos := lp[:endIdx].find('conclusion')) > -1 and looksLikeTitle(lp[:endIdx], cpos, 'conclusion'):\n",
    "        # print(f\"Done conclusion {cpos}: {endIdx}\")\n",
    "        conclusion = lp[cpos:endIdx] + conclusion\n",
    "        return conclusion\n",
    "    else:\n",
    "        # it looks like the conclusion spans a page\n",
    "        conclusion = lp[:endIdx]\n",
    "        endIdx = None\n",
    "        if pIdx > 0:\n",
    "            pIdx -= 1\n",
    "            # print(f\"looking for conclusion at {pIdx}\")\n",
    "            page = pdf[pIdx].get_textpage().get_text_range()\n",
    "            lp = page.lower()\n",
    "            if (cpos := lp.find('conclusion')) > -1 and looksLikeTitle(lp[:endIdx], cpos, 'conclusion'):\n",
    "                conclusion = lp[cpos:] + conclusion\n",
    "                return conclusion\n",
    "            elif hailMary:\n",
    "                if len(conclusion) > MINCONCLLEN:\n",
    "                    # print(f\"Cant find conclusion, returning last chunk\")\n",
    "                    return conclusion\n",
    "                else: return lp + conclusion\n",
    "            else: return ''\n",
    "        else: return conclusion\n",
    "\n",
    "def getAbs(pdf, hailMary=False):\n",
    "    \"\"\"\n",
    "     THe abstract is between 'Abstract' and 'Introduction'\n",
    "    \"\"\"\n",
    "    logging.info('Trying to find abstract from pdf')\n",
    "    nPages = len(pdf)\n",
    "    done = False\n",
    "    pIdx = 0\n",
    "    abs = ''\n",
    "    startIdx = -1\n",
    "    endIdx = -1\n",
    "    abstract = ''\n",
    "    re1 = re.compile('\\W*abstract\\W*\\n')\n",
    "    while not done and pIdx < nPages:\n",
    "        page = pdf[pIdx].get_textpage().get_text_range()\n",
    "        lp = page.lower()\n",
    "        if (ax := lp.find('abstract')) >= 0:\n",
    "            m1 = reAbs.match(lp[:ax])\n",
    "            startIdx = ax\n",
    "            break\n",
    "        elif len(page) <= MINPAGELEN:\n",
    "            pIdx += 1\n",
    "            continue\n",
    "        else:\n",
    "            if hailMary:\n",
    "                # print(\"cannot find absract. return the whole page\")\n",
    "                return page\n",
    "            else: return ''\n",
    "    if (ix := lp[ax:].find('introduction')) >= 0:\n",
    "        # assume intro is on same page\n",
    "        abstract += lp[startIdx:(ax + ix)]\n",
    "        return abstract\n",
    "    elif pIdx + 1 < nPages:\n",
    "        # looks like the abstract runs to the next page\n",
    "        abstract += lp[startIdx:]\n",
    "        page = pdf[pIdx + 1].get_textpage().get_text_range()\n",
    "        lp = page.lower()\n",
    "        if (ix := lp.find('introduction')) >= 0:\n",
    "            abstract += lp[:ix]\n",
    "            return abstract\n",
    "        else:\n",
    "            if hailMary:\n",
    "                # add this page in\n",
    "                abstract += lp\n",
    "            return abstract\n",
    "    return ''\n",
    "    \n",
    "\n",
    "def looksLikeTitle(page, pos, title):\n",
    "    # we might have the keyword 'conclusion' say in the text or in a title. \n",
    "    # this is a heuristic way to figure that out.\n",
    "    # the heuristic is that a title is a relatively short string on a line\n",
    "    strOI = page[max(0, pos - TTLEXP): (pos + TTLEXP)]\n",
    "    theRE = re.compile('([^\\n]*' + title + 's?[^\\n]*)', re.MULTILINE|re.DOTALL)\n",
    "    while True:\n",
    "        m1 = re.search(theRE, strOI)\n",
    "        if not m1: break\n",
    "        if len(m1[1]) <= MAXTITLELEN: return True\n",
    "        strOI = strOI[m1.end():]\n",
    "    return False\n",
    "\n",
    "# should use queryLLM.ipynb\n",
    "def queryOpenai(query: list[dict] = [],\n",
    "               instr: str = 'You are a helpful assistant.',\n",
    "               temperature: float= 0.0,\n",
    "               ) -> (str, list[str]):\n",
    "    qObj = [{\"role\": \"system\", \"content\": instr}]\n",
    "    qObj.extend(query)\n",
    "    response = openai.ChatCompletion.create(\n",
    "                   model = CMODEL,\n",
    "                   messages = qObj,\n",
    "                   temperature = temperature)\n",
    "    answers = [x['message']['content'] for x in response['choices']]\n",
    "    return response, answers\n",
    "\n",
    "\n",
    "def getOpenaiSummary(abs: str='', concl:str = '')->list[str]:\n",
    "    queryAC = [{\"role\": \"user\", \n",
    "                \"content\": f\"\"\"Given the paper abstract {'and conclusion ' if len(concl) > 10 else ''}below, answer the following questions. \n",
    "\n",
    "Questions:\n",
    "1. What is the paper about?\n",
    "2. What do the authors plan to show?\n",
    "3. Why is it significant?\n",
    "4. How do they intend to do it?\n",
    "5. What are the results?\n",
    "\n",
    "Abstract:\n",
    "{abs}\n",
    "\n",
    "{'Conclusion: ' + f'{chr(10)}{concl}' if len(concl) > 10 else ''}\n",
    "\"\"\"}]\n",
    "    instr = \"You are a scientific researcher who has read thousands of papers and can accurately summarize the contents.\"\n",
    "    resp, ans = queryOpenai(queryAC, instr)\n",
    "    return re.split('\\n+', ans[0])\n",
    "\n",
    "def queryPalmText(query: str,\n",
    "                  temperature: float = 0.0,\n",
    "                  model: str = gMODEL,\n",
    "                  fobj = None) -> (str, list[str]):\n",
    "    queryObj = query\n",
    "    palmResp = palm.generate_text(\n",
    "        model = gMODEL,\n",
    "        prompt = query,\n",
    "        temperature = temperature,\n",
    "        candidate_count = 1,\n",
    "        safety_settings = SAFETY\n",
    "    )\n",
    "    answers = [x['output'] for x in palmResp.candidates]\n",
    "    if fobj is not None:\n",
    "        fobg.write(f\"\\n{'-'*10}\\nPROMPT: {query}\\nTEMP: {temperature}\\n\")\n",
    "        for a in answers:\n",
    "            fobj.write(f\"\\n--\\n{a}\")\n",
    "        fobj.flush()\n",
    "    return palmResp, answers\n",
    "\n",
    "def getGoogleSummary(abs:str = '', concl:str = ''):\n",
    "    query = f\"\"\"Given the paper abstract {'and conclusion ' if len(concl) > 10 else ''}below, answer the following questions. \n",
    "\n",
    "Questions:\n",
    "1. What is the paper about?\n",
    "2. What do the authors plan to show?\n",
    "3. Why is it significant?\n",
    "4. How do they intend to do it?\n",
    "5. What are the results?\n",
    "\n",
    "Abstract:\n",
    "{abs}\n",
    "\n",
    "{'Conclusion: ' + f'{chr(10)}{concl}' if len(concl) > 10 else ''}\n",
    "\"\"\"\n",
    " \n",
    "    response, answers = queryPalmText(query)\n",
    "    if DEBUG > 0:\n",
    "        print('RESPONSE\\n', response)\n",
    "        print('\\n----\\nANSWERS\\n', answers) \n",
    "    if len(answers) > 0:\n",
    "        return re.split('\\n+', answers[0])\n",
    "    else: return None\n",
    "\n",
    "    \n",
    "# the main method\n",
    "def getArxivSummaries(topic:str = 'LLM',  # comma separated terms\n",
    "                      num:int = 10, \n",
    "                      llm: str = 'openai',  # 'google' or 'openai'\n",
    "                      startDate: str = None, # YYYYMMDD\n",
    "                      endDate: str = None,\n",
    "                      noConclusionsOK: bool = True,\n",
    "                      pdfCacheDir: str = None, \n",
    "                      fname:str = None,   # uses default name if None\n",
    "                     ): \n",
    "    if pdfCacheDir is None:\n",
    "        pdfCacheDir = PDFCACHEDIR\n",
    "    if startDate is not None and endDate is not None:\n",
    "        dumpDir = os.path.join(pdfCacheDir, f\"{topic.replace(' ', '_')}_{startDate}_{endDate}\")\n",
    "    else:\n",
    "        dumpDir = os.path.join(pdfCacheDir, f\"{topic.replace(' ', '_')}\")\n",
    "    if os.path.exists(dumpDir):\n",
    "        dumpDir += f\"_{random.randint(0, 1000)}\"\n",
    "    logging.info(f\"Main. query: {topic}, numer: {num}, dumpdir: {dumpDir}\")\n",
    "    print(f\"Main. query: {topic}, numer: {num}, dumpdir: {dumpDir}\")\n",
    "\n",
    "    os.makedirs(dumpDir, exist_ok=True)\n",
    "    if fname is None:\n",
    "        fname = os.path.join(dumpDir, \"summaries.csv\")\n",
    "    print('Getting references from Arxiv')\n",
    "    docs = getPapers(topic, num, startDate=startDate, endDate=endDate)\n",
    "    print(f\"Num papers found: {len(docs)}\")\n",
    "    print('Downloading and parsing papers')\n",
    "    docs = addChunks(docs, noConclusionsOK, dumpDir)\n",
    "    results = []\n",
    "    print('Querying llm')\n",
    "    for d in docs[:num]:\n",
    "        logging.info(f\"Summarizing {d['paper'].title[:40]}\")\n",
    "        print(f\"Summarizing {d['paper'].title[:40]}\")\n",
    "        pinfo = [d['paper'].title, d['paper'].entry_id, d['paper'].published.strftime('%Y-%m')]\n",
    "        if llm == 'openai':\n",
    "            ans = getOpenaiSummary(d['abstract'], d['conclusion'])\n",
    "        elif llm == 'google':\n",
    "            ans = getGoogleSummary(d['abstract'], d['conclusion'])\n",
    "        else:\n",
    "            logging.error('Unknoen llm')\n",
    "            print('Unknown llm')\n",
    "            return\n",
    "        if ans is None:\n",
    "            continue\n",
    "        pinfo.extend(ans)\n",
    "        if len(ans) != 5:\n",
    "            logging.error(f\"chatgpt answer not right length\")\n",
    "            print('chatgpt answer not right length')\n",
    "            print(pinfo)\n",
    "        else:\n",
    "            results.append(pinfo)\n",
    "    try:\n",
    "        dfr = pd.DataFrame(results, \n",
    "                           columns=['title', 'url', 'date', 'about', 'aims', 'significance', 'methods', 'results'])\n",
    "        if fname is not None:\n",
    "            dfr.to_csv(fname, index=False)\n",
    "    except Exception as e:\n",
    "        dfr = None\n",
    "        try:\n",
    "            jres = json.dumps(results)\n",
    "            dumpRes = jres\n",
    "        except:\n",
    "            logging.error('cannot serialize to json')\n",
    "            print('cannot serialize to json')\n",
    "            dumpRes = str(results)\n",
    "        with open(fname, 'w') as ox:\n",
    "            ox.write(dumpRes)\n",
    "        logging.info(f\"Dumped results to {fname}\")\n",
    "        print(f\"Dumped results to {fname}\")\n",
    "    if not dfr is None:\n",
    "        display(dfr)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e54428-56ab-4011-a9c6-25ca234017ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main. query: essay scoring, numer: 30, dumpdir: /Users/kp/projects/documents/genSummary/essay_scoring\n",
      "Getting references from Arxiv\n",
      "arxiv query: abs:essay scoring\n",
      "Num papers found: 60\n",
      "Downloading and parsing papers\n",
      "Querying llm\n",
      "Summarizing An Automated System for Essay Scoring of\n",
      "Summarizing Automated assessment of non-native learn\n",
      "Summarizing Many Hands Make Light Work: Using Essay \n",
      "Summarizing Toward Educator-focused Automated Scorin\n",
      "Summarizing Automatic Essay Scoring in a Brazilian S\n",
      "Summarizing Cognitively Aided Zero-Shot Automatic Es\n",
      "Summarizing Transformer-based Joint Modelling for Au\n",
      "Summarizing Improving Performance of Automated Essay\n",
      "Summarizing H-AES: Towards Automated Essay Scoring f\n",
      "Summarizing Automated Topical Component Extraction U\n",
      "Summarizing Prompt- and Trait Relation-aware Cross-p\n",
      "Summarizing Automated essay scoring with string kern\n",
      "Summarizing My Teacher Thinks The World Is Flat! Int\n",
      "Summarizing Corruption Is Not All Bad: Incorporating\n",
      "Summarizing DREsS: Dataset for Rubric-based Essay Sc\n",
      "Summarizing The Effectiveness of a Dynamic Loss Func\n",
      "Summarizing Essay-BR: a Brazilian Corpus of Essays\n",
      "Summarizing AES Systems Are Both Overstable And Over\n",
      "Summarizing FABRIC: Automated Scoring and Feedback G\n",
      "Summarizing Prompt Agnostic Essay Scorer: A Domain G\n",
      "Summarizing Using Active Learning Methods to Strateg\n",
      "Summarizing Exploring Automated Essay Scoring for No\n",
      "Summarizing Rubric-Specific Approach to Automated Es\n",
      "Summarizing Prompting Large Language Models for Zero\n",
      "Summarizing Frustratingly Simple Prompting-based Tex\n",
      "Summarizing Autoregressive Score Generation for Mult\n",
      "Summarizing Review of feedback in Automated Essay Sc\n",
      "Summarizing Data Augmentation for Automated Essay Sc\n",
      "Summarizing Can Large Language Models Automatically \n",
      "Summarizing UKARA 1.0 Challenge Track 1: Automatic S\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>about</th>\n",
       "      <th>aims</th>\n",
       "      <th>significance</th>\n",
       "      <th>methods</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Automated System for Essay Scoring of Onlin...</td>\n",
       "      <td>http://arxiv.org/abs/1611.02815v1</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>1. The paper is about an automated system for ...</td>\n",
       "      <td>2. The authors plan to show that their propose...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors have developed an online exam b...</td>\n",
       "      <td>5. The results of the paper indicate that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Automated assessment of non-native learner ess...</td>\n",
       "      <td>http://arxiv.org/abs/1612.00729v1</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>1. The paper is about Automatic Essay Scoring ...</td>\n",
       "      <td>2. The authors plan to show which specific lin...</td>\n",
       "      <td>3. The study is significant because while AES ...</td>\n",
       "      <td>4. The authors intend to do this by modeling t...</td>\n",
       "      <td>5. The results show that the feature set used ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Many Hands Make Light Work: Using Essay Traits...</td>\n",
       "      <td>http://arxiv.org/abs/2102.00781v1</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>1. The paper is about the use of multi-task le...</td>\n",
       "      <td>2. The authors aim to demonstrate that their M...</td>\n",
       "      <td>3. The research is significant because it offe...</td>\n",
       "      <td>4. The authors use a multi-task learning appro...</td>\n",
       "      <td>5. The results show that the MTL-based BiLSTM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toward Educator-focused Automated Scoring Syst...</td>\n",
       "      <td>http://arxiv.org/abs/2112.11973v1</td>\n",
       "      <td>2021-12</td>\n",
       "      <td>1. The paper is about improving automated essa...</td>\n",
       "      <td>2. The authors plan to show how neural network...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors intend to do this by employing ...</td>\n",
       "      <td>5. The results of the paper are not explicitly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic Essay Scoring in a Brazilian Scenario</td>\n",
       "      <td>http://arxiv.org/abs/2401.00095v1</td>\n",
       "      <td>2023-12</td>\n",
       "      <td>1. The paper is about a new Automatic Essay Sc...</td>\n",
       "      <td>2. The authors plan to show that their AES alg...</td>\n",
       "      <td>3. The significance of this research lies in i...</td>\n",
       "      <td>4. They intend to do this by leveraging advanc...</td>\n",
       "      <td>5. The abstract does not provide specific resu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cognitively Aided Zero-Shot Automatic Essay Gr...</td>\n",
       "      <td>http://arxiv.org/abs/2102.11258v1</td>\n",
       "      <td>2021-02</td>\n",
       "      <td>1. The paper is about the problem of zero-shot...</td>\n",
       "      <td>2. The authors aim to demonstrate that using g...</td>\n",
       "      <td>3. The significance of this research lies in i...</td>\n",
       "      <td>4. The authors intend to achieve their goal by...</td>\n",
       "      <td>5. The results of the experiments show that us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Transformer-based Joint Modelling for Automati...</td>\n",
       "      <td>http://arxiv.org/abs/2404.08655v1</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>1. The paper is about improving Automated Essa...</td>\n",
       "      <td>2. The authors plan to show that their propose...</td>\n",
       "      <td>3. The study is significant because it address...</td>\n",
       "      <td>4. The authors intend to do this by proposing ...</td>\n",
       "      <td>5. The results show that the proposed method o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Improving Performance of Automated Essay Scori...</td>\n",
       "      <td>http://arxiv.org/abs/2203.00354v2</td>\n",
       "      <td>2022-03</td>\n",
       "      <td>1. The paper is about improving the performanc...</td>\n",
       "      <td>2. The authors plan to show that their propose...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors intend to achieve their goal by...</td>\n",
       "      <td>5. The results showed that the performance of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>H-AES: Towards Automated Essay Scoring for Hindi</td>\n",
       "      <td>http://arxiv.org/abs/2302.14635v1</td>\n",
       "      <td>2023-02</td>\n",
       "      <td>1. The paper is about the application of Natur...</td>\n",
       "      <td>2. The authors aim to demonstrate that AES can...</td>\n",
       "      <td>3. The study is significant because AES in Hin...</td>\n",
       "      <td>4. The authors train and evaluate their models...</td>\n",
       "      <td>5. The results of the study show that the auth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Automated Topical Component Extraction Using N...</td>\n",
       "      <td>http://arxiv.org/abs/2008.01809v1</td>\n",
       "      <td>2020-08</td>\n",
       "      <td>1. The paper is about linking automated writin...</td>\n",
       "      <td>2. The authors plan to show that their method,...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. They intend to do this by using the attenti...</td>\n",
       "      <td>5. The results show that T-Cattn outperforms a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Prompt- and Trait Relation-aware Cross-prompt ...</td>\n",
       "      <td>http://arxiv.org/abs/2305.16826v1</td>\n",
       "      <td>2023-05</td>\n",
       "      <td>1. The paper is about improving Automated Essa...</td>\n",
       "      <td>2. The authors plan to show that their propose...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors intend to do this by encoding p...</td>\n",
       "      <td>5. The results of the experiments show that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Automated essay scoring with string kernels an...</td>\n",
       "      <td>http://arxiv.org/abs/1804.07954v2</td>\n",
       "      <td>2018-04</td>\n",
       "      <td>1. The paper is about a novel approach to auto...</td>\n",
       "      <td>2. The authors aim to demonstrate that their a...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors intend to validate their approa...</td>\n",
       "      <td>5. The results of the study indicate that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>My Teacher Thinks The World Is Flat! Interpret...</td>\n",
       "      <td>http://arxiv.org/abs/2012.13872v1</td>\n",
       "      <td>2020-12</td>\n",
       "      <td>1. The paper is about understanding and interp...</td>\n",
       "      <td>2. The authors plan to show how these AES syst...</td>\n",
       "      <td>3. The study is significant because AES system...</td>\n",
       "      <td>4. The authors intend to do this by utilizing ...</td>\n",
       "      <td>5. The results show that the AES systems teste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Corruption Is Not All Bad: Incorporating Disco...</td>\n",
       "      <td>http://arxiv.org/abs/2010.06137v1</td>\n",
       "      <td>2020-10</td>\n",
       "      <td>1. The paper is about a new unsupervised pre-t...</td>\n",
       "      <td>2. The authors plan to show that their propose...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors intend to do this by introducin...</td>\n",
       "      <td>5. The results show that the proposed method s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DREsS: Dataset for Rubric-based Essay Scoring ...</td>\n",
       "      <td>http://arxiv.org/abs/2402.16733v1</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>1. The paper is about the development and rele...</td>\n",
       "      <td>2. The authors aim to show that their dataset,...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors collected real-classroom data f...</td>\n",
       "      <td>5. The results show that the DREsS dataset, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Effectiveness of a Dynamic Loss Function i...</td>\n",
       "      <td>http://arxiv.org/abs/2305.10447v1</td>\n",
       "      <td>2023-05</td>\n",
       "      <td>1. The paper is about the use of a dynamic los...</td>\n",
       "      <td>2. The authors aim to demonstrate that their d...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors intend to achieve their goal by...</td>\n",
       "      <td>5. The results of the study show that the dyna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Essay-BR: a Brazilian Corpus of Essays</td>\n",
       "      <td>http://arxiv.org/abs/2105.09081v1</td>\n",
       "      <td>2021-05</td>\n",
       "      <td>1. The paper is about Automatic Essay Scoring ...</td>\n",
       "      <td>2. The authors plan to show the challenges pos...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors have created a large corpus of ...</td>\n",
       "      <td>5. The results of the paper are not explicitly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AES Systems Are Both Overstable And Oversensit...</td>\n",
       "      <td>http://arxiv.org/abs/2109.11728v3</td>\n",
       "      <td>2021-09</td>\n",
       "      <td>1. The paper is about exploring the mechanisms...</td>\n",
       "      <td>2. The authors plan to show the reasons behind...</td>\n",
       "      <td>3. The study is significant because AES system...</td>\n",
       "      <td>4. The authors intend to use recent advances i...</td>\n",
       "      <td>5. The results indicate that, despite being tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FABRIC: Automated Scoring and Feedback Generat...</td>\n",
       "      <td>http://arxiv.org/abs/2310.05191v1</td>\n",
       "      <td>2023-10</td>\n",
       "      <td>1. The paper is about the development of FABRI...</td>\n",
       "      <td>2. The authors aim to show that FABRIC can gen...</td>\n",
       "      <td>3. The study is significant because it address...</td>\n",
       "      <td>4. The authors intend to do this by first crea...</td>\n",
       "      <td>5. The results show that the use of DREsS and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Prompt Agnostic Essay Scorer: A Domain General...</td>\n",
       "      <td>http://arxiv.org/abs/2008.01441v1</td>\n",
       "      <td>2020-08</td>\n",
       "      <td>1. The paper is about the development of a new...</td>\n",
       "      <td>2. The authors plan to show that their PAES me...</td>\n",
       "      <td>3. The research is significant because it addr...</td>\n",
       "      <td>4. The authors intend to use a neural network ...</td>\n",
       "      <td>5. The results of the experiments carried out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Using Active Learning Methods to Strategically...</td>\n",
       "      <td>http://arxiv.org/abs/2301.00628v2</td>\n",
       "      <td>2023-01</td>\n",
       "      <td>1. The paper is about the use of three active ...</td>\n",
       "      <td>2. The authors plan to show that these active ...</td>\n",
       "      <td>3. The study is significant because it address...</td>\n",
       "      <td>4. The authors used the three active learning ...</td>\n",
       "      <td>5. The results showed that all three active le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Exploring Automated Essay Scoring for Nonnativ...</td>\n",
       "      <td>http://arxiv.org/abs/1706.03335v3</td>\n",
       "      <td>2017-06</td>\n",
       "      <td>1. The paper is about the development and test...</td>\n",
       "      <td>2. The authors aim to demonstrate that their A...</td>\n",
       "      <td>3. The significance of this research lies in i...</td>\n",
       "      <td>4. The authors conducted an experiment where t...</td>\n",
       "      <td>5. The results of the experiment showed that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rubric-Specific Approach to Automated Essay Sc...</td>\n",
       "      <td>http://arxiv.org/abs/2309.02740v1</td>\n",
       "      <td>2023-09</td>\n",
       "      <td>1. The paper is about improving the performanc...</td>\n",
       "      <td>2. The authors plan to show that their propose...</td>\n",
       "      <td>3. The research is significant because it addr...</td>\n",
       "      <td>4. The authors intend to do this by designing ...</td>\n",
       "      <td>5. The results show that the proposed AES mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Prompting Large Language Models for Zero-shot ...</td>\n",
       "      <td>http://arxiv.org/abs/2404.04941v1</td>\n",
       "      <td>2024-04</td>\n",
       "      <td>1. The paper is about the application of large...</td>\n",
       "      <td>2. The authors aim to demonstrate that their p...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors use ChatGPT to break down writi...</td>\n",
       "      <td>5. The results of the experiments show that MT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Frustratingly Simple Prompting-based Text Deno...</td>\n",
       "      <td>http://arxiv.org/abs/2402.15931v1</td>\n",
       "      <td>2024-02</td>\n",
       "      <td>1. The paper is about a novel approach to auto...</td>\n",
       "      <td>2. The authors plan to show that even subtle m...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors intend to do this by employing ...</td>\n",
       "      <td>5. The results of the study show that in most ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Autoregressive Score Generation for Multi-trai...</td>\n",
       "      <td>http://arxiv.org/abs/2403.08332v1</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>1. The paper is about the application of pre-t...</td>\n",
       "      <td>2. The authors aim to demonstrate that their p...</td>\n",
       "      <td>3. The significance of this study lies in its ...</td>\n",
       "      <td>4. The authors intend to achieve their objecti...</td>\n",
       "      <td>5. The results of the study show that the prop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Review of feedback in Automated Essay Scoring</td>\n",
       "      <td>http://arxiv.org/abs/2307.05553v1</td>\n",
       "      <td>2023-07</td>\n",
       "      <td>1. The paper is about the evolution and import...</td>\n",
       "      <td>2. The authors aim to show the significance of...</td>\n",
       "      <td>3. The paper is significant because it provide...</td>\n",
       "      <td>4. The authors review previous research on fee...</td>\n",
       "      <td>5. The authors conclude that assigning scores ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Data Augmentation for Automated Essay Scoring ...</td>\n",
       "      <td>http://arxiv.org/abs/2210.12809v5</td>\n",
       "      <td>2022-10</td>\n",
       "      <td>1. The paper is about automated essay scoring,...</td>\n",
       "      <td>2. The authors plan to show the effectiveness ...</td>\n",
       "      <td>3. The paper's significance lies in its potent...</td>\n",
       "      <td>4. The authors intend to empirically test the ...</td>\n",
       "      <td>5. The results are not explicitly stated in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Can Large Language Models Automatically Score ...</td>\n",
       "      <td>http://arxiv.org/abs/2403.06149v2</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>1. The paper is about testing the ability of L...</td>\n",
       "      <td>2. The authors plan to show whether these LLMs...</td>\n",
       "      <td>3. The study is significant because it explore...</td>\n",
       "      <td>4. The authors intend to do this by experiment...</td>\n",
       "      <td>5. The results of the study revealed that the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>UKARA 1.0 Challenge Track 1: Automatic Short-A...</td>\n",
       "      <td>http://arxiv.org/abs/2002.12540v1</td>\n",
       "      <td>2020-02</td>\n",
       "      <td>1. The paper is about the authors' third-place...</td>\n",
       "      <td>2. The authors plan to show their approach to ...</td>\n",
       "      <td>3. The significance of this paper lies in its ...</td>\n",
       "      <td>4. The authors used two different models for t...</td>\n",
       "      <td>5. The results showed that single models with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0   An Automated System for Essay Scoring of Onlin...   \n",
       "1   Automated assessment of non-native learner ess...   \n",
       "2   Many Hands Make Light Work: Using Essay Traits...   \n",
       "3   Toward Educator-focused Automated Scoring Syst...   \n",
       "4     Automatic Essay Scoring in a Brazilian Scenario   \n",
       "5   Cognitively Aided Zero-Shot Automatic Essay Gr...   \n",
       "6   Transformer-based Joint Modelling for Automati...   \n",
       "7   Improving Performance of Automated Essay Scori...   \n",
       "8    H-AES: Towards Automated Essay Scoring for Hindi   \n",
       "9   Automated Topical Component Extraction Using N...   \n",
       "10  Prompt- and Trait Relation-aware Cross-prompt ...   \n",
       "11  Automated essay scoring with string kernels an...   \n",
       "12  My Teacher Thinks The World Is Flat! Interpret...   \n",
       "13  Corruption Is Not All Bad: Incorporating Disco...   \n",
       "14  DREsS: Dataset for Rubric-based Essay Scoring ...   \n",
       "15  The Effectiveness of a Dynamic Loss Function i...   \n",
       "16             Essay-BR: a Brazilian Corpus of Essays   \n",
       "17  AES Systems Are Both Overstable And Oversensit...   \n",
       "18  FABRIC: Automated Scoring and Feedback Generat...   \n",
       "19  Prompt Agnostic Essay Scorer: A Domain General...   \n",
       "20  Using Active Learning Methods to Strategically...   \n",
       "21  Exploring Automated Essay Scoring for Nonnativ...   \n",
       "22  Rubric-Specific Approach to Automated Essay Sc...   \n",
       "23  Prompting Large Language Models for Zero-shot ...   \n",
       "24  Frustratingly Simple Prompting-based Text Deno...   \n",
       "25  Autoregressive Score Generation for Multi-trai...   \n",
       "26      Review of feedback in Automated Essay Scoring   \n",
       "27  Data Augmentation for Automated Essay Scoring ...   \n",
       "28  Can Large Language Models Automatically Score ...   \n",
       "29  UKARA 1.0 Challenge Track 1: Automatic Short-A...   \n",
       "\n",
       "                                  url     date  \\\n",
       "0   http://arxiv.org/abs/1611.02815v1  2016-11   \n",
       "1   http://arxiv.org/abs/1612.00729v1  2016-12   \n",
       "2   http://arxiv.org/abs/2102.00781v1  2021-02   \n",
       "3   http://arxiv.org/abs/2112.11973v1  2021-12   \n",
       "4   http://arxiv.org/abs/2401.00095v1  2023-12   \n",
       "5   http://arxiv.org/abs/2102.11258v1  2021-02   \n",
       "6   http://arxiv.org/abs/2404.08655v1  2024-03   \n",
       "7   http://arxiv.org/abs/2203.00354v2  2022-03   \n",
       "8   http://arxiv.org/abs/2302.14635v1  2023-02   \n",
       "9   http://arxiv.org/abs/2008.01809v1  2020-08   \n",
       "10  http://arxiv.org/abs/2305.16826v1  2023-05   \n",
       "11  http://arxiv.org/abs/1804.07954v2  2018-04   \n",
       "12  http://arxiv.org/abs/2012.13872v1  2020-12   \n",
       "13  http://arxiv.org/abs/2010.06137v1  2020-10   \n",
       "14  http://arxiv.org/abs/2402.16733v1  2024-02   \n",
       "15  http://arxiv.org/abs/2305.10447v1  2023-05   \n",
       "16  http://arxiv.org/abs/2105.09081v1  2021-05   \n",
       "17  http://arxiv.org/abs/2109.11728v3  2021-09   \n",
       "18  http://arxiv.org/abs/2310.05191v1  2023-10   \n",
       "19  http://arxiv.org/abs/2008.01441v1  2020-08   \n",
       "20  http://arxiv.org/abs/2301.00628v2  2023-01   \n",
       "21  http://arxiv.org/abs/1706.03335v3  2017-06   \n",
       "22  http://arxiv.org/abs/2309.02740v1  2023-09   \n",
       "23  http://arxiv.org/abs/2404.04941v1  2024-04   \n",
       "24  http://arxiv.org/abs/2402.15931v1  2024-02   \n",
       "25  http://arxiv.org/abs/2403.08332v1  2024-03   \n",
       "26  http://arxiv.org/abs/2307.05553v1  2023-07   \n",
       "27  http://arxiv.org/abs/2210.12809v5  2022-10   \n",
       "28  http://arxiv.org/abs/2403.06149v2  2024-03   \n",
       "29  http://arxiv.org/abs/2002.12540v1  2020-02   \n",
       "\n",
       "                                                about  \\\n",
       "0   1. The paper is about an automated system for ...   \n",
       "1   1. The paper is about Automatic Essay Scoring ...   \n",
       "2   1. The paper is about the use of multi-task le...   \n",
       "3   1. The paper is about improving automated essa...   \n",
       "4   1. The paper is about a new Automatic Essay Sc...   \n",
       "5   1. The paper is about the problem of zero-shot...   \n",
       "6   1. The paper is about improving Automated Essa...   \n",
       "7   1. The paper is about improving the performanc...   \n",
       "8   1. The paper is about the application of Natur...   \n",
       "9   1. The paper is about linking automated writin...   \n",
       "10  1. The paper is about improving Automated Essa...   \n",
       "11  1. The paper is about a novel approach to auto...   \n",
       "12  1. The paper is about understanding and interp...   \n",
       "13  1. The paper is about a new unsupervised pre-t...   \n",
       "14  1. The paper is about the development and rele...   \n",
       "15  1. The paper is about the use of a dynamic los...   \n",
       "16  1. The paper is about Automatic Essay Scoring ...   \n",
       "17  1. The paper is about exploring the mechanisms...   \n",
       "18  1. The paper is about the development of FABRI...   \n",
       "19  1. The paper is about the development of a new...   \n",
       "20  1. The paper is about the use of three active ...   \n",
       "21  1. The paper is about the development and test...   \n",
       "22  1. The paper is about improving the performanc...   \n",
       "23  1. The paper is about the application of large...   \n",
       "24  1. The paper is about a novel approach to auto...   \n",
       "25  1. The paper is about the application of pre-t...   \n",
       "26  1. The paper is about the evolution and import...   \n",
       "27  1. The paper is about automated essay scoring,...   \n",
       "28  1. The paper is about testing the ability of L...   \n",
       "29  1. The paper is about the authors' third-place...   \n",
       "\n",
       "                                                 aims  \\\n",
       "0   2. The authors plan to show that their propose...   \n",
       "1   2. The authors plan to show which specific lin...   \n",
       "2   2. The authors aim to demonstrate that their M...   \n",
       "3   2. The authors plan to show how neural network...   \n",
       "4   2. The authors plan to show that their AES alg...   \n",
       "5   2. The authors aim to demonstrate that using g...   \n",
       "6   2. The authors plan to show that their propose...   \n",
       "7   2. The authors plan to show that their propose...   \n",
       "8   2. The authors aim to demonstrate that AES can...   \n",
       "9   2. The authors plan to show that their method,...   \n",
       "10  2. The authors plan to show that their propose...   \n",
       "11  2. The authors aim to demonstrate that their a...   \n",
       "12  2. The authors plan to show how these AES syst...   \n",
       "13  2. The authors plan to show that their propose...   \n",
       "14  2. The authors aim to show that their dataset,...   \n",
       "15  2. The authors aim to demonstrate that their d...   \n",
       "16  2. The authors plan to show the challenges pos...   \n",
       "17  2. The authors plan to show the reasons behind...   \n",
       "18  2. The authors aim to show that FABRIC can gen...   \n",
       "19  2. The authors plan to show that their PAES me...   \n",
       "20  2. The authors plan to show that these active ...   \n",
       "21  2. The authors aim to demonstrate that their A...   \n",
       "22  2. The authors plan to show that their propose...   \n",
       "23  2. The authors aim to demonstrate that their p...   \n",
       "24  2. The authors plan to show that even subtle m...   \n",
       "25  2. The authors aim to demonstrate that their p...   \n",
       "26  2. The authors aim to show the significance of...   \n",
       "27  2. The authors plan to show the effectiveness ...   \n",
       "28  2. The authors plan to show whether these LLMs...   \n",
       "29  2. The authors plan to show their approach to ...   \n",
       "\n",
       "                                         significance  \\\n",
       "0   3. The significance of this paper lies in its ...   \n",
       "1   3. The study is significant because while AES ...   \n",
       "2   3. The research is significant because it offe...   \n",
       "3   3. The significance of this paper lies in its ...   \n",
       "4   3. The significance of this research lies in i...   \n",
       "5   3. The significance of this research lies in i...   \n",
       "6   3. The study is significant because it address...   \n",
       "7   3. The significance of this paper lies in its ...   \n",
       "8   3. The study is significant because AES in Hin...   \n",
       "9   3. The significance of this paper lies in its ...   \n",
       "10  3. The significance of this paper lies in its ...   \n",
       "11  3. The significance of this paper lies in its ...   \n",
       "12  3. The study is significant because AES system...   \n",
       "13  3. The significance of this paper lies in its ...   \n",
       "14  3. The significance of this paper lies in its ...   \n",
       "15  3. The significance of this paper lies in its ...   \n",
       "16  3. The significance of this paper lies in its ...   \n",
       "17  3. The study is significant because AES system...   \n",
       "18  3. The study is significant because it address...   \n",
       "19  3. The research is significant because it addr...   \n",
       "20  3. The study is significant because it address...   \n",
       "21  3. The significance of this research lies in i...   \n",
       "22  3. The research is significant because it addr...   \n",
       "23  3. The significance of this paper lies in its ...   \n",
       "24  3. The significance of this paper lies in its ...   \n",
       "25  3. The significance of this study lies in its ...   \n",
       "26  3. The paper is significant because it provide...   \n",
       "27  3. The paper's significance lies in its potent...   \n",
       "28  3. The study is significant because it explore...   \n",
       "29  3. The significance of this paper lies in its ...   \n",
       "\n",
       "                                              methods  \\\n",
       "0   4. The authors have developed an online exam b...   \n",
       "1   4. The authors intend to do this by modeling t...   \n",
       "2   4. The authors use a multi-task learning appro...   \n",
       "3   4. The authors intend to do this by employing ...   \n",
       "4   4. They intend to do this by leveraging advanc...   \n",
       "5   4. The authors intend to achieve their goal by...   \n",
       "6   4. The authors intend to do this by proposing ...   \n",
       "7   4. The authors intend to achieve their goal by...   \n",
       "8   4. The authors train and evaluate their models...   \n",
       "9   4. They intend to do this by using the attenti...   \n",
       "10  4. The authors intend to do this by encoding p...   \n",
       "11  4. The authors intend to validate their approa...   \n",
       "12  4. The authors intend to do this by utilizing ...   \n",
       "13  4. The authors intend to do this by introducin...   \n",
       "14  4. The authors collected real-classroom data f...   \n",
       "15  4. The authors intend to achieve their goal by...   \n",
       "16  4. The authors have created a large corpus of ...   \n",
       "17  4. The authors intend to use recent advances i...   \n",
       "18  4. The authors intend to do this by first crea...   \n",
       "19  4. The authors intend to use a neural network ...   \n",
       "20  4. The authors used the three active learning ...   \n",
       "21  4. The authors conducted an experiment where t...   \n",
       "22  4. The authors intend to do this by designing ...   \n",
       "23  4. The authors use ChatGPT to break down writi...   \n",
       "24  4. The authors intend to do this by employing ...   \n",
       "25  4. The authors intend to achieve their objecti...   \n",
       "26  4. The authors review previous research on fee...   \n",
       "27  4. The authors intend to empirically test the ...   \n",
       "28  4. The authors intend to do this by experiment...   \n",
       "29  4. The authors used two different models for t...   \n",
       "\n",
       "                                              results  \n",
       "0   5. The results of the paper indicate that the ...  \n",
       "1   5. The results show that the feature set used ...  \n",
       "2   5. The results show that the MTL-based BiLSTM ...  \n",
       "3   5. The results of the paper are not explicitly...  \n",
       "4   5. The abstract does not provide specific resu...  \n",
       "5   5. The results of the experiments show that us...  \n",
       "6   5. The results show that the proposed method o...  \n",
       "7   5. The results showed that the performance of ...  \n",
       "8   5. The results of the study show that the auth...  \n",
       "9   5. The results show that T-Cattn outperforms a...  \n",
       "10  5. The results of the experiments show that th...  \n",
       "11  5. The results of the study indicate that the ...  \n",
       "12  5. The results show that the AES systems teste...  \n",
       "13  5. The results show that the proposed method s...  \n",
       "14  5. The results show that the DREsS dataset, pa...  \n",
       "15  5. The results of the study show that the dyna...  \n",
       "16  5. The results of the paper are not explicitly...  \n",
       "17  5. The results indicate that, despite being tr...  \n",
       "18  5. The results show that the use of DREsS and ...  \n",
       "19  5. The results of the experiments carried out ...  \n",
       "20  5. The results showed that all three active le...  \n",
       "21  5. The results of the experiment showed that t...  \n",
       "22  5. The results show that the proposed AES mode...  \n",
       "23  5. The results of the experiments show that MT...  \n",
       "24  5. The results of the study show that in most ...  \n",
       "25  5. The results of the study show that the prop...  \n",
       "26  5. The authors conclude that assigning scores ...  \n",
       "27  5. The results are not explicitly stated in th...  \n",
       "28  5. The results of the study revealed that the ...  \n",
       "29  5. The results showed that single models with ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getArxivSummaries(topic = 'essay scoring', \n",
    "                  num = 30, \n",
    "                  llm = 'openai', \n",
    "                  startDate = None,\n",
    "                  endDate = None,\n",
    "                  noConclusionsOK = True,\n",
    "                  pdfCacheDir = '/Users/kp/projects/documents/genSummary',\n",
    "                  fname = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
